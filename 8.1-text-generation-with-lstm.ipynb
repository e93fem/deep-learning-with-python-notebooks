{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with LSTM\n",
    "\n",
    "This notebook contains the code samples found in Chapter 8, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "----\n",
    "\n",
    "[...]\n",
    "\n",
    "## Implementing character-level LSTM text generation\n",
    "\n",
    "\n",
    "Let's put these ideas in practice in a Keras implementation. The first thing we need is a lot of text data that we can use to learn a \n",
    "language model. You could use any sufficiently large text file or set of text files -- Wikipedia, the Lord of the Rings, etc. In this \n",
    "example we will use some of the writings of Nietzsche, the late-19th century German philosopher (translated to English). The language model \n",
    "we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the \n",
    "English language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's start by downloading the corpus and converting it to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\FEM\\\\.keras\\\\datasets\\\\nietzsche.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we will extract partially-overlapping sequences of length `maxlen`, one-hot encode them and pack them in a 3D Numpy array `x` of \n",
    "shape `(sequences, maxlen, unique_characters)`. Simultaneously, we prepare a array `y` containing the corresponding targets: the one-hot \n",
    "encoded characters that come right after each extracted sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200281\n",
      "Unique characters: 59\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Our network is a single `LSTM` layer followed by a `Dense` classifier and softmax over all possible characters. But let us note that \n",
    "recurrent neural networks are not the only way to do sequence data generation; 1D convnets also have proven extremely successful at it in \n",
    "recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our targets are one-hot encoded, we will use `categorical_crossentropy` as the loss to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it\n",
    "\n",
    "\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "* 1) Drawing from the model a probability distribution over the next character given the text available so far\n",
    "* 2) Reweighting the distribution to a certain \"temperature\"\n",
    "* 3) Sampling the next character at random according to the reweighted distribution\n",
    "* 4) Adding the new character at the end of the available text\n",
    "\n",
    "This is the code we use to reweight the original probability distribution coming out of the model, \n",
    "and draw a character index from it (the \"sampling function\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, this is the loop where we repeatedly train and generated text. We start generating text using a range of different temperatures \n",
    "after every epoch. This allows us to see how the generated text evolves as the model starts converging, as well as the impact of \n",
    "temperature in the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 130s 647us/step - loss: 2.0070\n",
      "--- Generating with seed: \"a\n",
      "kind of cruelty of the intellectual conscience and taste, \"\n",
      "------ temperature: 0.2\n",
      "a\n",
      "kind of cruelty of the intellectual conscience and taste, the consequently the supress of the self--as the are and and spirit of the self--and disturing the supress of the are the consequently of the self--the consequently the supress of the are the consequently the self--and the supress of the supress of the supress of the consequently the more the supress of the deems of the supre and the self--and the reases of the supress of the supress of the supres\n",
      "------ temperature: 0.5\n",
      "--and the reases of the supress of the supress of the supress and possible of the suppiciontity as all with the reased the perhaps the suple and to the most not the first of the the are praise the enception into the be the self-a the feel the conseque and soul the suppocies and spirit and the hight the fect in the neters which the preferition of the reffinity and to the prederition. the ordition of the man who conseading them has every and good the alter, \n",
      "------ temperature: 1.0\n",
      "f the man who conseading them has every and good the alter, almoself\n",
      "-and anfire bystarm soul mentacally nevelapial thrundmetnowiuls \"or mye\n",
      "of alless souid his with the wroty or \"ronited ost the lifeccive one onty bse it is enawally freenciing inetolone fles to suess, willsbines. the \"vionce of the condute,\" than bst and  one, as notion of the termangnout overy\n",
      "him\n",
      "the goely to, the \"gooth of who hafe discaral to does reffeen indectians, oy they of day ne\n",
      "------ temperature: 1.2\n",
      " hafe discaral to does reffeen indectians, oy they of day nevem knecedral in\n",
      "victaplemsts is, cunmoral be the geffice juysicest.-\n",
      "loruemon kenoutoce uptice, diveacersces, him\n",
      "espain \"necesssed--on exiemstainicm. his weaks deild in the )afteses beyemop-\"fur, whth who compars rendirnce inetarry or alyst kind, and apphiso\n",
      "viruts of mystonsforime now un\n",
      "instates bristrd us and firuton \"duch gree ruwh untille putrey wourd right,\", \"free a nlites ontentuse ond f\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 134s 670us/step - loss: 1.6463\n",
      "--- Generating with seed: \"ised\n",
      "over this fearful unknown, how can this domain of freed\"\n",
      "------ temperature: 0.2\n",
      "ised\n",
      "over this fearful unknown, how can this domain of freedom to the sense and the sense to the self-conception of the sense the sense the self-conception of the self-conciunted and the sense to the more of the distroust the self-conception of the sense the self-conception of the strength, and the self-cance the sense the self-conciuness of the something of the sense of the consideration of the someteres the sense to the theress of the for the self-consid\n",
      "------ temperature: 0.5\n",
      "ometeres the sense to the theress of the for the self-consident the spiritual more and distracted to the difficult the once the conyss and the yount the present that thought to have be\n",
      "whole inclean, which is and the origin, intellection of the self-for the mist to subject the string volition of the sense of the and the the will been disent to the simint to the similical concelence of the old against and the way as the commands is not be or the takents to \n",
      "------ temperature: 1.0\n",
      "nst and the way as the commands is not be or the takents to commomplated cannen                                          rea easings\n",
      "and valies, do r this gocruid of the other not him, such thous viril. in the angilic of the enstreasing\n",
      "with much of the milaly metaphy\n",
      "althe inowine of which show it an occis faines hid countenis, an,\n",
      "that benessive,--be deivifulies and this session of deteccality and to poptrated can bet invility of mecises i not religing t\n",
      "------ temperature: 1.2\n",
      "nd to poptrated can bet invility of mecises i not religing that for the opinicilgues iivere; for who mangestance tohiler, for lict mame far asers, youd ast ordenls in humanious,--paratific, foo irrater in ths way emoriousaratian, was was wroncy nom\n",
      "the hever thouous, are, atchrescograble have thather foblishh of creacilitfut and when the sim to which mo\"kenored:\n",
      "in thus. in thing ig the\n",
      "-oppocal feeth anything. theseysers\n",
      "mir simes, what\n",
      "hoyesviluluber-rer\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 129s 644us/step - loss: 1.5501\n",
      "--- Generating with seed: \", from fitness, is deduced\n",
      "justification. so also: an opinio\"\n",
      "------ temperature: 0.2\n",
      ", from fitness, is deduced\n",
      "justification. so also: an opinion of the world of the supers of the same and man in the world and the spirit of the supers of the spirit and sense of the spirit of the super and the possible the super the masters of the supers of the conclusion of the problem of the super and the super strength of the supers of the distrust and man of the condividence of the supers the super and the supers of the supers, and the more assife the \n",
      "------ temperature: 0.5\n",
      "super and the supers of the supers, and the more assife the sense with of the other one who has itself that the which the free stronges of a be faction of the truth as a person the called the impulses of the expression of man, which is soul and deep to the concluded for\n",
      "and sourplean of conceidity and must a conclusicianity of the self conclusion as itself and who contradies and fasion and and perhaps assest and suffering it is and person and be gald, ther\n",
      "------ temperature: 1.0\n",
      "haps assest and suffering it is and person and be gald, there is\n",
      "theusau poss as, the scrimed indeed of disitless invinged so\n",
      "adearting a servial. incencever incaieicaliates by not lines therrogainting its of spariful con, taking be to what regards--knerneable--the lotesbstance with onerely itstolminary congilfuls\n",
      "in mestages, and the araking and the cause and ecimpousical, we disperagest,\n",
      "will faithsical instinct, ny-mut first leasent and every privarimat\n",
      "------ temperature: 1.2\n",
      "ithsical instinct, ny-mut first leasent and every privarimating, the weakes. s\n",
      "pararily as somening sa delightly platur-lemned caps--ngened--long, and to woad pri withzany and catnoticanter, with mesietics standsuce training which home, be the grady maum firily--it--with the empiha-finn of self condrvation. nouls onchkeck what that,man;\n",
      "him. hy regalt toushivic the point on hhe facc enouth grow the gregruatje of must miscccratly.\n",
      "in deadaring this\n",
      "forvals:\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 129s 645us/step - loss: 1.5052\n",
      "--- Generating with seed: \"\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "=astrology and the like.=--it is presumable that the o\"\n",
      "------ temperature: 0.2\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "=astrology and the like.=--it is presumable that the ourselves of the sentiments of the present to the stand of the self-former the stands of the feeling to the stands to the self-something to the self-something the sentiments of the stands of the feeling to the self-something to the stands to the self-former and the spirit to the world of the fundamentally of the stands of the spirit to the reality of the depth the feeling to the free something the \n",
      "------ temperature: 0.5\n",
      " reality of the depth the feeling to the free something the one of the world of this sertations itsests with the extent desire to serious to be religious to possible, on the discrinting the spirit in the something to be stoncish of the\n",
      "society to be all the deep and in the pays of the continuments and into the deceptions in the most pattomive which the fament to the segulation of serious for the best still in the desire the world and proposition of the mor\n",
      "------ temperature: 1.0\n",
      "est still in the desire the world and proposition of the mor as see\n",
      "with lower talplex, with the thring by the demortal about segiated, he he taste with it refertion,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and disposed or both usuradion of life and otherionable as very vice as denilities why german perloated becauses,, what which a fearw--the history are kerone the ourself discopsyshoul insestire society, found for even we positivality, by self-vatt of ance: it is to shathing distince seem.\n",
      "\n",
      "1f\n",
      "------ temperature: 1.2\n",
      ", by self-vatt of ance: it is to shathing distince seem.\n",
      "\n",
      "1fo ourthershougner. the machr, sentibenes, plar, has\n",
      "\"myself for erises to this o\n",
      "perition of heart oo using has otheral.\n",
      "the whre eprial gerity.ly--but it things , it sadd finer.\n",
      "\n",
      "reatwix, find\n",
      "itself them so hymomly\n",
      "afalitations, tone will the\n",
      "stanct\n",
      "hymomed upon de. to-only no she: one seegeon allly est these up flre! he does so io thromingly blent their moriment forgesd, does\n",
      "there illemness se\n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 130s 649us/step - loss: 1.4779\n",
      "--- Generating with seed: \"need of, had to fashion\n",
      "it for myself, counterfeiting it or \"\n",
      "------ temperature: 0.2\n",
      "need of, had to fashion\n",
      "it for myself, counterfeiting it or the sense of the sense of the subject the spirit of the consequence of the spirits and the sense of the subject the sense of the consideration of the man and all the sense of the life is in the sense of the sense of the consideration of the consideration of the subject the sense of the spirit is a self-as the problem the sense of the subject and the spirits of the sense of the deception of the con\n",
      "------ temperature: 0.5\n",
      "ect and the spirits of the sense of the deception of the contemptation of the feelings has a commanding estraying something of the her self-and the sense in the instinct, as all that is all the perfection of the faction of a religion of the falseness of the eass\n",
      "man and even the\n",
      "surrender the abbeine of the most probably be one has all that he serious the eront in the destroration which in the heart to is love the spirit, and far execut to means of the cou\n",
      "------ temperature: 1.0\n",
      "rt to is love the spirit, and far execut to means of the could a distiveina,\n",
      "that all fair his paysic ritied possies, like? for europe has and collective--men be understand. that a proper,\n",
      "loghest, what just against baffes\n",
      "man about entervivation far perhaps,\" basures and the one may geniuse-everys\n",
      ". whose parred.\n",
      " so\n",
      "be the lofline, on physegnackous decentifice all, whole steps with the sacrte-and mentom us, he seaciines and netsucerious parsical interpre\n",
      "------ temperature: 1.2\n",
      "d mentom us, he seaciines and netsucerious parsical interprehaps\n",
      "art by thellyse us: the orilit to proub it. one often \"philosophy from\n",
      "of\n",
      "or understood,\" this sertarjasbedment heught first\n",
      "\"taluradity, in it: not to the\n",
      "yon, moteed and quite\n",
      "which mannes ofly, as\n",
      "at the depth usefly a a loves\n",
      "would ner pectyired injungier of only casephed rubfeldis nature on dyrand sotimal-senige, impole-valentiblechts that agyness of althrio\n",
      "coverm of (an higher on our v\n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 132s 657us/step - loss: 1.4558\n",
      "--- Generating with seed: \"nt useful.=--therefore, whether psychological observation\n",
      "is\"\n",
      "------ temperature: 0.2\n",
      "nt useful.=--therefore, whether psychological observation\n",
      "is a man the seldest of the seldest of the subject something the seldest of the seldest of the will the subject of the subject in the seldest and subject and seldest of the seldest of the sense of the same soul, the world of the seem and subject the same something the subject of the subject to the seldest of the seldim and something the subject in the same sun an explaines and seldiment of the said \n",
      "------ temperature: 0.5\n",
      "ject in the same sun an explaines and seldiment of the said of a heart experience. we lake and repulsion with\n",
      "something with the present and the act as like something man is good every command of the command to into enjoy, fasion that is further to degree and seldiment of the false; it is commandly, which is all the seldiment the consider from such a man and man is everything the subject something the sense of the consider and spirit, the pressitusm of the\n",
      "------ temperature: 1.0\n",
      " the sense of the consider and spirit, the pressitusm of the sort, lives the master of\n",
      "heart was \"most orderked prollt as knowledger: \"one will has art goilation, and acquire acts for every s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trivitad men of\n",
      "cause, i. it is well, he in the hungest a solutuct with the let this \"gondent of pofsibityded call sea\n",
      "ofignitte, and must oneselve\n",
      "light: that undrodition),\n",
      "more \"callly\n",
      "belie est alcos ecentlation and admilal mutt--above \"if we pain). every well excer\n",
      "------ temperature: 1.2\n",
      "ation and admilal mutt--above \"if we pain). every well excerts more  god the in nurgle\n",
      "virtuo inservicalive a perhad from its tentationly might\n",
      "shnute and twree some soul. they,\n",
      "or\n",
      "the\n",
      "deyticianch. espe)itionly cersence its time-nates our geniuine vent \"untede! than longre perance while\n",
      "ierism. i revent them good hulfat is opilive\n",
      "to the act in regard lid unequally themselves\n",
      "fouste a callesth solimite his remande, soin coneviit as apqueit, 'most viltem co\n",
      "epoch 7\n",
      "Epoch 1/1\n",
      " 77184/200281 [==========>...................] - ETA: 1:20 - loss: 1.4314"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9486ed95c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     model.fit(x, y,\n\u001b[0;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m               epochs=1)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Select a text seed at random\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, a low temperature results in extremely repetitive and predictable text, but where local structure is highly realistic: in \n",
    "particular, all words (a word being a local pattern of characters) are real English words. With higher temperatures, the generated text \n",
    "becomes more interesting, surprising, even creative; it may sometimes invent completely new words that sound somewhat plausible (such as \n",
    "\"eterned\" or \"troveration\"). With a high temperature, the local structure starts breaking down and most words look like semi-random strings \n",
    "of characters. Without a doubt, here 0.5 is the most interesting temperature for text generation in this specific setup. Always experiment \n",
    "with multiple sampling strategies! A clever balance between learned structure and randomness is what makes generation interesting.\n",
    "\n",
    "Note that by training a bigger model, longer, on more data, you can achieve generated samples that will look much more coherent and \n",
    "realistic than ours. But of course, don't expect to ever generate any meaningful text, other than by random chance: all we are doing is \n",
    "sampling data from a statistical model of which characters come after which characters. Language is a communication channel, and there is \n",
    "a distinction between what communications are about, and the statistical structure of the messages in which communications are encoded. To \n",
    "evidence this distinction, here is a thought experiment: what if human language did a better job at compressing communications, much like \n",
    "our computers do with most of our digital communications? Then language would be no less meaningful, yet it would lack any intrinsic \n",
    "statistical structure, thus making it impossible to learn a language model like we just did.\n",
    "\n",
    "\n",
    "## Take aways\n",
    "\n",
    "* We can generate discrete sequence data by training a model to predict the next tokens(s) given previous tokens.\n",
    "* In the case of text, such a model is called a \"language model\" and could be based on either words or characters.\n",
    "* Sampling the next token requires balance between adhering to what the model judges likely, and introducing randomness.\n",
    "* One way to handle this is the notion of _softmax temperature_. Always experiment with different temperatures to find the \"right\" one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
